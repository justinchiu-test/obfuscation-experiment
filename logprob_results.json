[
  {
    "file": "modeling_llama.py",
    "total_logprob": -1124.704825781077,
    "tokens": 2545
  },
  {
    "file": "modeling_llama_obfuscated.py",
    "total_logprob": -1193.7692391528035,
    "tokens": 1668
  }
]