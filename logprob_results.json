[
  {
    "file": "modeling_llama.py",
    "total_logprob": -1120.0769727980091,
    "tokens": 2545
  },
  {
    "file": "modeling_llama_obfuscated_min.py",
    "total_logprob": -1177.943828819257,
    "tokens": 1475
  }
]